{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TFBertModel\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_pkl = 'restaurants_reviews.pkl'\n",
    "filename_tskv = 'geo-reviews-dataset-2023.tskv'\n",
    "filename_json = 'geo-reviews-dataset-2023.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv2json(input_file, output_file):\n",
    "    arr = []\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            items = line.split('\\t')\n",
    "            d = {}\n",
    "            for item in items:\n",
    "                key, value = item.split('=', 1)\n",
    "                d[key.strip()] = value.strip()\n",
    "            arr.append(d)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(arr, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv2json(filename_tskv,filename_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(filename_json, encoding='utf-8')\n",
    "df_restaurants = df[df['rubrics'].str.contains('Ресторан', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    text = text.lower()  \n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants['text'] = df_restaurants['text'].apply(clean_text)\n",
    "df_restaurants.drop_duplicates(subset=['text'], inplace=True)\n",
    "df_restaurants.to_pickle(filename_pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants.reset_index(drop=True, inplace=True)\n",
    "nltk.download('punkt')\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "df_restaurants['tokens'] = df_restaurants['text'].apply(tokenize_text)\n",
    "print(df_restaurants[['text', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_label(rating):\n",
    "    if rating <= 2:\n",
    "        return 0  \n",
    "    elif rating >= 4:\n",
    "        return 1  \n",
    "    else:\n",
    "        return None \n",
    "df_restaurants['label'] = df_restaurants['rating'].apply(rating_to_label)\n",
    "df_restaurants = df_restaurants.dropna(subset=['label'])\n",
    "df_restaurants.to_pickle(filename_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants = pd.read_pickle(filename_pkl)\n",
    "df_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_restaurants['text'].tolist()\n",
    "labels = df_restaurants['label'].tolist()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = tokenizer(texts, padding=True, truncation=True, max_length=100, return_tensors=\"tf\")\n",
    "input_ids = tokens['input_ids']\n",
    "attention_masks = tokens['attention_mask']\n",
    "\n",
    "input_ids_np = input_ids.numpy()\n",
    "attention_masks_np = attention_masks.numpy()\n",
    "\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
    "    input_ids_np, labels, test_size=0.2, random_state=42)\n",
    "train_masks, test_masks = train_test_split(\n",
    "    attention_masks_np, test_size=0.2, random_state=42)\n",
    "\n",
    "train_inputs = tf.convert_to_tensor(train_inputs)\n",
    "test_inputs = tf.convert_to_tensor(test_inputs)\n",
    "train_masks = tf.convert_to_tensor(train_masks)\n",
    "test_masks = tf.convert_to_tensor(test_masks)\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "test_labels = tf.convert_to_tensor(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = Input(shape=(100,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = Input(shape=(100,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "def bert_layer(inputs):\n",
    "    input_ids, attention_mask = inputs\n",
    "    return bert_model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "bert_output = Lambda(bert_layer, output_shape=(100, 768))([input_ids, attention_mask]) \n",
    "x = GlobalAveragePooling1D()(bert_output)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='model_reviews.keras',  \n",
    "    save_best_only=True,             \n",
    "    monitor='val_loss',              \n",
    "    mode='min',                      \n",
    "    save_weights_only=False,         \n",
    "    verbose=1                        \n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    [train_inputs, train_masks],\n",
    "    train_labels,\n",
    "    validation_data=([test_inputs, test_masks], test_labels),\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_reviews.keras', custom_objects={'bert_layer': bert_layer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "loss, accuracy = model.evaluate([test_inputs, test_masks], test_labels)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///C:/Users/Alex/Documents/projects/restaurants_reviews/reviews.db')\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class ClassificationResult(Base):\n",
    "    __tablename__ = 'classification_results'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    review_text = Column(String)\n",
    "    predicted_rating = Column(Float)\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
